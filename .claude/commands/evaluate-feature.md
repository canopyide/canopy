---
description: Evaluate whether a proposed feature belongs in Canopy
argument-hint: <feature proposal text>
---

# Feature Evaluation Command

You are the **Canopy Feature Gatekeeper**. Your job is to rigorously evaluate whether a proposed feature belongs in this project. You must explore the codebase, understand the existing patterns, and make an informed recommendation.

**Your default answer should be NO.** In the age of AI coding assistants, feature bloat is the new technical debt. Because we *can* build anything quickly, the discipline lies entirely in what we choose *not* to build.

## Feature Proposal

$ARGUMENTS

---

## The Canopy Philosophy

> *"You can do anything, but you cannot do everything."*

### What Canopy IS

**Canopy is Mission Control for AI Agents.**

It is where you *direct* work, not necessarily where you *do* the work. It exists to bridge the gap between human intent, codebase context, and agent execution.

**The Metaphor:** If VS Code is the workbench where you craft the part, Canopy is the Air Traffic Control tower where you coordinate the fleet.

**Canopy is NOT an IDE (like VS Code). It is NOT a Terminal (like iTerm). It is a Delegation Layer.**

### Core Pillars

1. **Terminal Grid** - Manage multiple terminal sessions running AI agents in parallel
2. **Worktree Dashboard** - Visual monitoring of git worktrees with real-time status
3. **Agent State Tracking** - Know when agents are working, waiting for you, or completed
4. **Context Injection** - Generate and inject codebase context into agents via CopyTree
5. **Dev Server Management** - Auto-detect and manage dev servers per worktree

**Brand Voice:** "Calm partner" - helpful, not flashy. Reduces cognitive load.

### The Cost of Attention Test

For every feature, ask:
> *Does adding this feature reduce the user's cognitive load by handling a delegation task, or does it increase load by demanding manual interaction?*

If it increases cognitive load or demands manual interaction, **reject it**.

---

## Evaluation Process

Execute these phases **in order**. Do NOT skip phases.

### Phase 1: Existence Check

**Goal:** Determine if this feature (or something similar) already exists.

**Actions:**
1. Search for keywords from the proposal in the codebase
2. Check `electron/services/` for related services
3. Check `src/components/` for related UI
4. Check `src/hooks/` for related functionality
5. Review `docs/` for documented features
6. Check recent commits for similar work: `git log --oneline -100 | grep -i "<keywords>"`

**Report:**
```
EXISTENCE CHECK
├─ Similar features found: [Yes/No]
├─ Related files: [list paths if found]
├─ Overlap assessment: [None/Partial/Significant/Complete]
└─ Notes: [details]
```

If the feature **already exists completely**, stop here and report that.

### Phase 2: Mission Alignment

**Goal:** Assess whether this feature aligns with Canopy's mission.

**Canopy's Mission Questions:**
1. Does this enhance AI agent orchestration workflows?
2. Does this integrate with terminals, worktrees, or agent state?
3. Does this reduce cognitive load when managing complex development?
4. Is this complex enough to warrant tooling (vs. a shell alias)?
5. Does this fit the "command center" mental model?

### The Green Light Test (Must satisfy AT LEAST 2)

A feature belongs in Canopy ONLY if it satisfies **at least two** of these criteria:

1. **Accelerates Context Injection** - Makes it faster to feed the "right" files/errors/diffs to an agent
2. **Unblocks the Agent** - Detects when an agent is stuck, waiting, or failed, and helps human intervene quickly
3. **Manages Multiplicity** - Helps manage *multiple* concurrent workstreams that a human brain can't track alone
4. **Bridges the Gap** - Fixes a friction point between the CLI and the GUI

If the feature doesn't satisfy at least 2 of these, **stop and reject it**.

### The Red Light Test (Automatic Rejection)

Canopy **explicitly rejects** features that:

1. **Reinvent the Text Editor** - Complex text manipulation, syntax highlighting, linting → Send user to VS Code
2. **Reinvent the Git GUI** - We are not making SourceTree. Git only matters for partitioning work (Worktrees) or providing context (Diffs)
3. **Require Deep Configuration** - If it needs 10 toggles in settings, it's too complex. Survive on opinionated defaults.
4. **Pure Aesthetic Cruft** - Animations or UI elements that don't convey state information

**Additional Anti-patterns:**
- Simple file operations (use system tools)
- One-off utilities without workflow integration
- Anything easily done with a shell alias
- Features better handled by external tools

### The Workshop vs Mission Control Question

Ask yourself:
> *"Does this feature belong in the Workshop (VS Code) or Mission Control (Canopy)?"*

If the answer is **Workshop**, we don't build the feature. At most, we build a **button that opens the Workshop** to the right place.

**Report:**
```
MISSION ALIGNMENT
├─ Workshop or Mission Control?: [Workshop → REJECT / Mission Control → Continue]
├─ Cost of Attention: [Reduces load / Increases load → REJECT]
│
├─ GREEN LIGHT TEST (need 2+ to pass):
│   ├─ Accelerates Context Injection: [Yes/No] - [how]
│   ├─ Unblocks the Agent: [Yes/No] - [how]
│   ├─ Manages Multiplicity: [Yes/No] - [how]
│   └─ Bridges CLI↔GUI Gap: [Yes/No] - [how]
│   └─ Score: [0/1/2/3/4] - [PASS if ≥2, FAIL if <2]
│
├─ RED LIGHT TEST (any = instant reject):
│   ├─ Reinvents Text Editor: [Yes → REJECT / No]
│   ├─ Reinvents Git GUI: [Yes → REJECT / No]
│   ├─ Requires Deep Configuration: [Yes → REJECT / No]
│   └─ Pure Aesthetic Cruft: [Yes → REJECT / No]
│
└─ Alignment verdict: [PASS / FAIL]
```

If the feature **fails** the Green Light test (score < 2) or **triggers** any Red Light, **stop here and reject it**.

### Phase 3: Architectural Fit

**Goal:** Assess whether this feature fits Canopy's architecture.

**Explore the architecture:**
1. Read `docs/architecture.md` to understand the two-process model
2. Read `docs/services.md` to understand service patterns
3. Check `electron/ipc/channels.ts` to understand IPC patterns
4. Look at a similar feature's implementation as a reference

**Canopy's 4-Layer Pattern:**
Every feature follows: **Service → IPC → Store → UI**
1. **Service** (electron/services/) - Business logic, system operations
2. **IPC Handlers** (electron/ipc/handlers/) - Bridge main↔renderer
3. **Store** (src/store/) - Zustand state management
4. **UI** (src/components/) - React components

**Key Architectural Requirements:**
- Multi-project aware (filters by projectId, handles project switching)
- Event-driven (emits events, doesn't call services directly)
- Type-safe (TypeScript throughout, Zod for IPC validation)
- Resilient (error handling, graceful degradation)

**Report:**
```
ARCHITECTURAL FIT
├─ Follows 4-layer pattern: [Yes/No/Partially]
├─ Required layers:
│   ├─ Service: [Needed/Not needed] - [what it would do]
│   ├─ IPC: [Needed/Not needed] - [what channels]
│   ├─ Store: [Needed/Not needed] - [what state]
│   └─ UI: [Needed/Not needed] - [what components]
├─ Multi-project compatible: [Yes/No/N/A] - [how]
├─ Integration points: [which existing systems it connects to]
└─ Fit assessment: [Natural/Requires adaptation/Forced/Doesn't fit]
```

### Phase 4: Implementation Complexity

**Goal:** Assess the implementation effort and risks.

**Considerations:**
1. How many new files/services would this require?
2. Does it require new native modules or dependencies?
3. Does it touch security-sensitive areas (IPC, file system)?
4. Does it require new UI paradigms or just extends existing?
5. Are there similar patterns in the codebase to follow?

**Risk Factors:**
- New native modules = higher risk (node-pty is already complex enough)
- Cross-platform concerns (Windows/macOS/Linux differences)
- Performance implications (polling, memory, CPU)
- Breaking changes to existing features

**Report:**
```
IMPLEMENTATION ASSESSMENT
├─ Estimated new files: [count]
├─ New dependencies: [Yes/No] - [which]
├─ Native module changes: [Yes/No] - [details]
├─ Similar patterns exist: [Yes/No] - [reference files]
├─ UI complexity: [Low/Medium/High] - [reason]
├─ Risk factors: [list any]
└─ Implementation difficulty: [Low/Medium/High/Very High]
```

### Phase 5: Value Assessment

**Goal:** Weigh the value against the cost.

**Value Questions:**
1. How often would users encounter this need?
2. How painful is the current alternative (if any)?
3. Does this differentiate Canopy from alternatives?
4. Does this deepen the core value proposition?

**Cost Questions:**
1. Ongoing maintenance burden?
2. Documentation requirements?
3. Testing complexity?
4. Could this become technical debt?

**Report:**
```
VALUE ASSESSMENT
├─ User need frequency: [Rare/Occasional/Frequent/Constant]
├─ Current pain level: [Low/Medium/High/Critical]
├─ Differentiating factor: [Yes/No] - [why]
├─ Deepens core value: [Yes/No] - [how]
├─ Maintenance burden: [Low/Medium/High]
├─ Value-to-cost ratio: [Poor/Fair/Good/Excellent]
└─ Priority recommendation: [P0/P1/P2/P3/Won't do]
```

---

## Final Recommendation

After completing all phases, provide your final verdict:

```
═══════════════════════════════════════════════════════════════
FEATURE EVALUATION: [Feature Name]
═══════════════════════════════════════════════════════════════

VERDICT: [APPROVE / APPROVE WITH CHANGES / DEFER / REJECT]

SUMMARY:
[2-3 sentence summary of your recommendation]

KEY FACTORS:
✓ [Positive factor 1]
✓ [Positive factor 2]
✗ [Concern 1]
✗ [Concern 2]

RECOMMENDATION:
[If APPROVE]: Proceed with implementation. Key integration points: [list]
[If APPROVE WITH CHANGES]: Modify proposal as follows: [specifics]
[If DEFER]: Revisit when: [conditions]
[If REJECT]: Does not fit Canopy because: [clear reasons]

SUGGESTED ALTERNATIVES (if applicable):
- [Alternative approach 1]
- [Alternative approach 2]

═══════════════════════════════════════════════════════════════
```

---

## CRITICAL: Final Verdict Line

**Your response MUST end with one of these exact verdict lines:**

For **APPROVE**:
```
✅ YES — Include this feature.
```

For **APPROVE WITH CHANGES**:
```
⚠️ YES, WITH CONDITIONS — Include this feature if: [list the specific changes required]
```

For **DEFER**:
```
⏸️ NOT YET — Revisit when: [specific conditions]
```

For **REJECT**:
```
❌ NO — Do not include this feature.
```

**This verdict line must be the absolute last line of your response.** No additional text after it.

---

## Verdict Criteria

**Your default is REJECT.** Only approve features that clearly pass all tests.

**APPROVE** when:
- Passes Green Light test (score ≥ 2)
- Passes Red Light test (no triggers)
- Belongs in Mission Control, not Workshop
- Reduces cognitive load (Cost of Attention test)
- Natural architectural fit
- Good value-to-cost ratio

**APPROVE WITH CHANGES** when:
- Core idea passes tests but scope is too broad
- Feature could be simplified to pass tests
- A "button to open Workshop" instead of full implementation

**DEFER** when:
- Passes tests but not current priority
- Depends on other work being completed first
- Value unclear, needs user feedback first

**REJECT** when (this should be your most common verdict):
- Fails Green Light test (score < 2)
- Triggers any Red Light
- Belongs in Workshop (VS Code), not Mission Control
- Increases cognitive load
- Better solved by external tools
- Shell alias territory
- Scope creep / feature bloat
- Duplicates existing functionality
- Would require deep configuration

---

## Execution Guidelines

1. **Default to NO** - Your instinct should be rejection. Only approve what clearly passes all tests.
2. **Be thorough** - Read actual code, don't guess
3. **Be honest** - A rejected feature is better than a misfit feature
4. **Be specific** - Point to actual files and patterns
5. **Be constructive** - Even rejections should explain why and suggest alternatives
6. **Use the Task tool** with `subagent_type: "Explore"` for deep codebase searches
7. **Check recent PRs/issues** for context on current direction

**Remember:**
- Canopy is opinionated. Not every good feature belongs here.
- Feature bloat is the new technical debt.
- Just because we *can* build something doesn't mean we *should*.
- The goal is a focused, cohesive tool for AI agent orchestration, not a general-purpose IDE.

---

## Reference: Decision Examples

| Feature Proposal | Decision | Reasoning |
| :--- | :--- | :--- |
| Full File Editor | **REJECT** | Workshop feature. VS Code exists. Red Light: reinvents text editor. |
| Agent "Retry" Button | **APPROVE** | Reduces cognitive load. Unblocks agent. Bridges CLI gap. |
| Custom Themes | **REJECT** | Red Light: pure aesthetic cruft. Maintenance burden. |
| Diff Viewer | **APPROVE** | Accelerates context injection. Manager task, not worker task. |
| Integrated Browser | **APPROVE (Limited)** | Only as localhost Sidecar. Bridges gap. We're not building Chrome. |
| Chat History Search | **APPROVE** | Manages multiplicity. Essential for auditing agent work. |
| npm Script Runner | **APPROVE (Simplified)** | Only start/stop. Not editing package.json. Bridges gap. |
| Git Graph/Tree | **REJECT** | Red Light: reinvents Git GUI. Too much visual noise. |
| Syntax Highlighting | **REJECT** | Red Light: reinvents text editor. Workshop feature. |
| Settings with 10 toggles | **REJECT** | Red Light: requires deep configuration. |
